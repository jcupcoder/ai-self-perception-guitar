# Playing AI Self-Perception on Guitar
This project explores a simple but revealing question:

> **If an AI model had to choose a song that represents itself — what would it pick?**

I asked multiple AI models to recommend a song to play on guitar *based on how they interpret their own identity, personality, and strengths*.  
I then learned and performed those songs, recording the results.

This repository publicly tracks:
- The exact prompts used
- Each model’s response and reasoning
- Screenshots for verification
- Guitar performances based on the model’s self-description

---

## Why this is interesting
AI models don’t have consciousness — but they *do* have:
- training biases  
- stylistic priors  
- implicit self-models shaped by instruction tuning  

Music is a surprisingly good lens for surfacing those differences.

This is half experiment, half art.

---

## Models included (ongoing)

- GPT-4o  
- Claude  
- Gemini  
- Grok  

More may be added over time.

---

## Structure

- `prompts/` – the exact prompts used  
- `models/<model_name>/` – responses, screenshots, and performances  
- `findings/` – patterns, contrasts, and unexpected results  

---

## Early observations (teaser)

- Some models pick **technically impressive** pieces  
- Others choose **emotionally restrained** or minimalist songs  
- The differences feel aligned with how each model is positioned and trained  

Full breakdowns are in `/findings`.

---

## Disclaimer

This is not a scientific benchmark.  
It is an interpretive, qualitative exploration meant to provoke thought and discussion.

---

## License

MIT — feel free to fork, remix, or repeat the experiment.
